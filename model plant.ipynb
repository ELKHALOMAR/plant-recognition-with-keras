{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.utils import np_utils, normalize\n",
    "\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "import pickle\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=0.75)\n",
    "sess = tf.Session(config=tf.ConfigProto(gpu_options = gpu_options))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_in = open(\"xx.pickle\",\"rb\")\n",
    "x = pickle.load(pickle_in)\n",
    "\n",
    "pickle_in = open(\"yy.pickle\",\"rb\")\n",
    "y = pickle.load(pickle_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5265"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = x/255.0\n",
    "y = np_utils.to_categorical(y, 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "dense_layers = [6]\n",
    "layer_sizes = [25]\n",
    "conv_layers = [4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4-conv-25-nodes-6-dense-1563839324\n",
      "Train on 3685 samples, validate on 1580 samples\n",
      "Epoch 1/128\n",
      "3685/3685 [==============================] - 7s 2ms/sample - loss: 0.4745 - acc: 0.8207 - val_loss: 0.2945 - val_acc: 0.9167\n",
      "Epoch 2/128\n",
      "3685/3685 [==============================] - 3s 720us/sample - loss: 0.2828 - acc: 0.9167 - val_loss: 0.2785 - val_acc: 0.9167\n",
      "Epoch 3/128\n",
      "3685/3685 [==============================] - 3s 721us/sample - loss: 0.2761 - acc: 0.9167 - val_loss: 0.2753 - val_acc: 0.9167\n",
      "Epoch 4/128\n",
      "3685/3685 [==============================] - 3s 710us/sample - loss: 0.2744 - acc: 0.9167 - val_loss: 0.2746 - val_acc: 0.9167\n",
      "Epoch 5/128\n",
      "3685/3685 [==============================] - 3s 699us/sample - loss: 0.2742 - acc: 0.9167 - val_loss: 0.2743 - val_acc: 0.9167\n",
      "Epoch 6/128\n",
      "3685/3685 [==============================] - 3s 712us/sample - loss: 0.2740 - acc: 0.9167 - val_loss: 0.2742 - val_acc: 0.9167\n",
      "Epoch 7/128\n",
      "3685/3685 [==============================] - 3s 695us/sample - loss: 0.2741 - acc: 0.9167 - val_loss: 0.2740 - val_acc: 0.9167\n",
      "Epoch 8/128\n",
      "3685/3685 [==============================] - 3s 707us/sample - loss: 0.2740 - acc: 0.9167 - val_loss: 0.2742 - val_acc: 0.9167\n",
      "Epoch 9/128\n",
      "3685/3685 [==============================] - 3s 710us/sample - loss: 0.2738 - acc: 0.9167 - val_loss: 0.2738 - val_acc: 0.9167\n",
      "Epoch 10/128\n",
      "3685/3685 [==============================] - 3s 713us/sample - loss: 0.2739 - acc: 0.9167 - val_loss: 0.2741 - val_acc: 0.9167\n",
      "Epoch 11/128\n",
      "3685/3685 [==============================] - 3s 697us/sample - loss: 0.2740 - acc: 0.9167 - val_loss: 0.2743 - val_acc: 0.9167\n",
      "Epoch 12/128\n",
      "3685/3685 [==============================] - 3s 708us/sample - loss: 0.2739 - acc: 0.9167 - val_loss: 0.2741 - val_acc: 0.9167\n",
      "Epoch 13/128\n",
      "3685/3685 [==============================] - 3s 692us/sample - loss: 0.2739 - acc: 0.9167 - val_loss: 0.2744 - val_acc: 0.9167\n",
      "Epoch 14/128\n",
      "3685/3685 [==============================] - 3s 736us/sample - loss: 0.2739 - acc: 0.9167 - val_loss: 0.2737 - val_acc: 0.9167\n",
      "Epoch 15/128\n",
      "3685/3685 [==============================] - 3s 701us/sample - loss: 0.2739 - acc: 0.9167 - val_loss: 0.2741 - val_acc: 0.9167\n",
      "Epoch 16/128\n",
      "3685/3685 [==============================] - 3s 765us/sample - loss: 0.2738 - acc: 0.9167 - val_loss: 0.2738 - val_acc: 0.9167\n",
      "Epoch 17/128\n",
      "3685/3685 [==============================] - 3s 739us/sample - loss: 0.2739 - acc: 0.9167 - val_loss: 0.2738 - val_acc: 0.9167\n",
      "Epoch 18/128\n",
      "3685/3685 [==============================] - 3s 740us/sample - loss: 0.2740 - acc: 0.9167 - val_loss: 0.2739 - val_acc: 0.9167\n",
      "Epoch 19/128\n",
      "3685/3685 [==============================] - 3s 702us/sample - loss: 0.2741 - acc: 0.9167 - val_loss: 0.2738 - val_acc: 0.9167\n",
      "Epoch 20/128\n",
      "3685/3685 [==============================] - 3s 742us/sample - loss: 0.2738 - acc: 0.9167 - val_loss: 0.2740 - val_acc: 0.9167\n",
      "Epoch 21/128\n",
      "3685/3685 [==============================] - 3s 714us/sample - loss: 0.2738 - acc: 0.9167 - val_loss: 0.2739 - val_acc: 0.9167\n",
      "Epoch 22/128\n",
      "3685/3685 [==============================] - 3s 778us/sample - loss: 0.2737 - acc: 0.9167 - val_loss: 0.2747 - val_acc: 0.9167\n",
      "Epoch 23/128\n",
      "3685/3685 [==============================] - 3s 734us/sample - loss: 0.2737 - acc: 0.9167 - val_loss: 0.2738 - val_acc: 0.9167\n",
      "Epoch 24/128\n",
      "3685/3685 [==============================] - 3s 712us/sample - loss: 0.2737 - acc: 0.9167 - val_loss: 0.2738 - val_acc: 0.9167\n",
      "Epoch 25/128\n",
      "3685/3685 [==============================] - 3s 700us/sample - loss: 0.2738 - acc: 0.9167 - val_loss: 0.2740 - val_acc: 0.9167\n",
      "Epoch 26/128\n",
      "3685/3685 [==============================] - 3s 711us/sample - loss: 0.2737 - acc: 0.9167 - val_loss: 0.2740 - val_acc: 0.9167\n",
      "Epoch 27/128\n",
      "3685/3685 [==============================] - 3s 685us/sample - loss: 0.2738 - acc: 0.9167 - val_loss: 0.2741 - val_acc: 0.9167\n",
      "Epoch 28/128\n",
      "3685/3685 [==============================] - 3s 704us/sample - loss: 0.2738 - acc: 0.9167 - val_loss: 0.2739 - val_acc: 0.9167\n",
      "Epoch 29/128\n",
      "3685/3685 [==============================] - 3s 694us/sample - loss: 0.2738 - acc: 0.9167 - val_loss: 0.2736 - val_acc: 0.9167\n",
      "Epoch 30/128\n",
      "3685/3685 [==============================] - 3s 689us/sample - loss: 0.2738 - acc: 0.9167 - val_loss: 0.2738 - val_acc: 0.9167\n",
      "Epoch 31/128\n",
      "3685/3685 [==============================] - 3s 695us/sample - loss: 0.2736 - acc: 0.9167 - val_loss: 0.2737 - val_acc: 0.9167\n",
      "Epoch 32/128\n",
      "3685/3685 [==============================] - 3s 692us/sample - loss: 0.2740 - acc: 0.9167 - val_loss: 0.2740 - val_acc: 0.9167\n",
      "Epoch 33/128\n",
      "3685/3685 [==============================] - 3s 725us/sample - loss: 0.2738 - acc: 0.9167 - val_loss: 0.2743 - val_acc: 0.9167\n",
      "Epoch 34/128\n",
      "3685/3685 [==============================] - 3s 685us/sample - loss: 0.2738 - acc: 0.9167 - val_loss: 0.2736 - val_acc: 0.9167\n",
      "Epoch 35/128\n",
      "3685/3685 [==============================] - 3s 711us/sample - loss: 0.2738 - acc: 0.9167 - val_loss: 0.2739 - val_acc: 0.9167\n",
      "Epoch 36/128\n",
      "3685/3685 [==============================] - 3s 718us/sample - loss: 0.2737 - acc: 0.9167 - val_loss: 0.2740 - val_acc: 0.9167\n",
      "Epoch 37/128\n",
      "3685/3685 [==============================] - 3s 720us/sample - loss: 0.2736 - acc: 0.9167 - val_loss: 0.2742 - val_acc: 0.9167\n",
      "Epoch 38/128\n",
      "3685/3685 [==============================] - 3s 727us/sample - loss: 0.2738 - acc: 0.9167 - val_loss: 0.2740 - val_acc: 0.9167\n",
      "Epoch 39/128\n",
      "3685/3685 [==============================] - 3s 717us/sample - loss: 0.2737 - acc: 0.9167 - val_loss: 0.2736 - val_acc: 0.9167\n",
      "Epoch 40/128\n",
      "3685/3685 [==============================] - 3s 685us/sample - loss: 0.2735 - acc: 0.9167 - val_loss: 0.2737 - val_acc: 0.9167\n",
      "Epoch 41/128\n",
      "3685/3685 [==============================] - 3s 700us/sample - loss: 0.2736 - acc: 0.9167 - val_loss: 0.2745 - val_acc: 0.9167\n",
      "Epoch 42/128\n",
      "3685/3685 [==============================] - 3s 707us/sample - loss: 0.2737 - acc: 0.9167 - val_loss: 0.2737 - val_acc: 0.9167\n",
      "Epoch 43/128\n",
      "3685/3685 [==============================] - 3s 708us/sample - loss: 0.2735 - acc: 0.9167 - val_loss: 0.2735 - val_acc: 0.9167\n",
      "Epoch 44/128\n",
      "3685/3685 [==============================] - 3s 702us/sample - loss: 0.2735 - acc: 0.9167 - val_loss: 0.2739 - val_acc: 0.9167\n",
      "Epoch 45/128\n",
      "3685/3685 [==============================] - 3s 725us/sample - loss: 0.2736 - acc: 0.9167 - val_loss: 0.2739 - val_acc: 0.9167\n",
      "Epoch 46/128\n",
      "3685/3685 [==============================] - 3s 705us/sample - loss: 0.2737 - acc: 0.9167 - val_loss: 0.2741 - val_acc: 0.9167\n",
      "Epoch 47/128\n",
      "3685/3685 [==============================] - 3s 752us/sample - loss: 0.2735 - acc: 0.9167 - val_loss: 0.2734 - val_acc: 0.9167\n",
      "Epoch 48/128\n",
      "3685/3685 [==============================] - 3s 694us/sample - loss: 0.2734 - acc: 0.9167 - val_loss: 0.2737 - val_acc: 0.9167\n",
      "Epoch 49/128\n",
      "3685/3685 [==============================] - 3s 700us/sample - loss: 0.2735 - acc: 0.9167 - val_loss: 0.2734 - val_acc: 0.9167\n",
      "Epoch 50/128\n",
      "3685/3685 [==============================] - 3s 687us/sample - loss: 0.2734 - acc: 0.9167 - val_loss: 0.2736 - val_acc: 0.9167\n",
      "Epoch 51/128\n",
      "3685/3685 [==============================] - 3s 702us/sample - loss: 0.2733 - acc: 0.9167 - val_loss: 0.2740 - val_acc: 0.9167\n",
      "Epoch 52/128\n",
      "3685/3685 [==============================] - 3s 688us/sample - loss: 0.2734 - acc: 0.9167 - val_loss: 0.2738 - val_acc: 0.9167\n",
      "Epoch 53/128\n",
      "3685/3685 [==============================] - 3s 705us/sample - loss: 0.2730 - acc: 0.9167 - val_loss: 0.2725 - val_acc: 0.9167\n",
      "Epoch 54/128\n",
      "3685/3685 [==============================] - 3s 687us/sample - loss: 0.2724 - acc: 0.9167 - val_loss: 0.2720 - val_acc: 0.9167\n",
      "Epoch 55/128\n",
      "3685/3685 [==============================] - 3s 698us/sample - loss: 0.2701 - acc: 0.9167 - val_loss: 0.2680 - val_acc: 0.9167\n",
      "Epoch 56/128\n",
      "3685/3685 [==============================] - 3s 697us/sample - loss: 0.2684 - acc: 0.9167 - val_loss: 0.2675 - val_acc: 0.9167\n",
      "Epoch 57/128\n",
      "3685/3685 [==============================] - 3s 736us/sample - loss: 0.2656 - acc: 0.9167 - val_loss: 0.2648 - val_acc: 0.9167\n",
      "Epoch 58/128\n",
      "3685/3685 [==============================] - 3s 738us/sample - loss: 0.2631 - acc: 0.9167 - val_loss: 0.2637 - val_acc: 0.9167\n",
      "Epoch 59/128\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3685/3685 [==============================] - 3s 746us/sample - loss: 0.2601 - acc: 0.9167 - val_loss: 0.2650 - val_acc: 0.9167\n",
      "Epoch 60/128\n",
      "3685/3685 [==============================] - 3s 732us/sample - loss: 0.2600 - acc: 0.9167 - val_loss: 0.2585 - val_acc: 0.9167\n",
      "Epoch 61/128\n",
      "3685/3685 [==============================] - 3s 751us/sample - loss: 0.2562 - acc: 0.9167 - val_loss: 0.2581 - val_acc: 0.9167\n",
      "Epoch 62/128\n",
      "3685/3685 [==============================] - 3s 748us/sample - loss: 0.2509 - acc: 0.9167 - val_loss: 0.2528 - val_acc: 0.9166\n",
      "Epoch 63/128\n",
      "3685/3685 [==============================] - 3s 740us/sample - loss: 0.2506 - acc: 0.9166 - val_loss: 0.2516 - val_acc: 0.9167\n",
      "Epoch 64/128\n",
      "3685/3685 [==============================] - 3s 725us/sample - loss: 0.2460 - acc: 0.9166 - val_loss: 0.2535 - val_acc: 0.9168\n",
      "Epoch 65/128\n",
      "3685/3685 [==============================] - 3s 761us/sample - loss: 0.2414 - acc: 0.9167 - val_loss: 0.2420 - val_acc: 0.9171\n",
      "Epoch 66/128\n",
      "3685/3685 [==============================] - 3s 721us/sample - loss: 0.2393 - acc: 0.9170 - val_loss: 0.2404 - val_acc: 0.9171\n",
      "Epoch 67/128\n",
      "3685/3685 [==============================] - 3s 764us/sample - loss: 0.2345 - acc: 0.9167 - val_loss: 0.2417 - val_acc: 0.9168\n",
      "Epoch 68/128\n",
      "3685/3685 [==============================] - 3s 895us/sample - loss: 0.2325 - acc: 0.9173 - val_loss: 0.2352 - val_acc: 0.9168\n",
      "Epoch 69/128\n",
      "3685/3685 [==============================] - 3s 766us/sample - loss: 0.2272 - acc: 0.9169 - val_loss: 0.2373 - val_acc: 0.9157\n",
      "Epoch 70/128\n",
      "3685/3685 [==============================] - 3s 725us/sample - loss: 0.2240 - acc: 0.9171 - val_loss: 0.2290 - val_acc: 0.9167\n",
      "Epoch 71/128\n",
      "3685/3685 [==============================] - 3s 751us/sample - loss: 0.2208 - acc: 0.9178 - val_loss: 0.2258 - val_acc: 0.9165\n",
      "Epoch 72/128\n",
      "3685/3685 [==============================] - 3s 729us/sample - loss: 0.2188 - acc: 0.9172 - val_loss: 0.2228 - val_acc: 0.9166\n",
      "Epoch 73/128\n",
      "3685/3685 [==============================] - 3s 774us/sample - loss: 0.2146 - acc: 0.9176 - val_loss: 0.2186 - val_acc: 0.9182\n",
      "Epoch 74/128\n",
      "3685/3685 [==============================] - 3s 733us/sample - loss: 0.2092 - acc: 0.9192 - val_loss: 0.2277 - val_acc: 0.9173\n",
      "Epoch 75/128\n",
      "3685/3685 [==============================] - 3s 740us/sample - loss: 0.2068 - acc: 0.9203 - val_loss: 0.2199 - val_acc: 0.9169\n",
      "Epoch 76/128\n",
      "3685/3685 [==============================] - 3s 741us/sample - loss: 0.2057 - acc: 0.9209 - val_loss: 0.2072 - val_acc: 0.9207\n",
      "Epoch 77/128\n",
      "3685/3685 [==============================] - 3s 727us/sample - loss: 0.2018 - acc: 0.9213 - val_loss: 0.2083 - val_acc: 0.9205\n",
      "Epoch 78/128\n",
      "3685/3685 [==============================] - 3s 762us/sample - loss: 0.1982 - acc: 0.9222 - val_loss: 0.2084 - val_acc: 0.9207\n",
      "Epoch 79/128\n",
      "3685/3685 [==============================] - 3s 747us/sample - loss: 0.1969 - acc: 0.9232 - val_loss: 0.2022 - val_acc: 0.9227\n",
      "Epoch 80/128\n",
      "3685/3685 [==============================] - 3s 789us/sample - loss: 0.1923 - acc: 0.9242 - val_loss: 0.2004 - val_acc: 0.9219\n",
      "Epoch 81/128\n",
      "3685/3685 [==============================] - 3s 732us/sample - loss: 0.1896 - acc: 0.9265 - val_loss: 0.2030 - val_acc: 0.9215\n",
      "Epoch 82/128\n",
      "3685/3685 [==============================] - 3s 741us/sample - loss: 0.1907 - acc: 0.9250 - val_loss: 0.2037 - val_acc: 0.9217\n",
      "Epoch 83/128\n",
      "3685/3685 [==============================] - 3s 700us/sample - loss: 0.1870 - acc: 0.9263 - val_loss: 0.2079 - val_acc: 0.9184\n",
      "Epoch 84/128\n",
      "3685/3685 [==============================] - 3s 770us/sample - loss: 0.1866 - acc: 0.9262 - val_loss: 0.2016 - val_acc: 0.9224\n",
      "Epoch 85/128\n",
      "3685/3685 [==============================] - 3s 881us/sample - loss: 0.1838 - acc: 0.9276 - val_loss: 0.1964 - val_acc: 0.9240\n",
      "Epoch 86/128\n",
      "3685/3685 [==============================] - 3s 840us/sample - loss: 0.1819 - acc: 0.9278 - val_loss: 0.1976 - val_acc: 0.9233\n",
      "Epoch 87/128\n",
      "3685/3685 [==============================] - 3s 826us/sample - loss: 0.1783 - acc: 0.9296 - val_loss: 0.1940 - val_acc: 0.9250\n",
      "Epoch 88/128\n",
      "3685/3685 [==============================] - 3s 844us/sample - loss: 0.1745 - acc: 0.9307 - val_loss: 0.1927 - val_acc: 0.9264\n",
      "Epoch 89/128\n",
      "3685/3685 [==============================] - 3s 778us/sample - loss: 0.1732 - acc: 0.9305 - val_loss: 0.1919 - val_acc: 0.9256\n",
      "Epoch 90/128\n",
      "3685/3685 [==============================] - 3s 821us/sample - loss: 0.1702 - acc: 0.9321 - val_loss: 0.1943 - val_acc: 0.9252\n",
      "Epoch 91/128\n",
      "3685/3685 [==============================] - 3s 713us/sample - loss: 0.1809 - acc: 0.9283 - val_loss: 0.2040 - val_acc: 0.9210\n",
      "Epoch 92/128\n",
      "3685/3685 [==============================] - 3s 726us/sample - loss: 0.1697 - acc: 0.9324 - val_loss: 0.1924 - val_acc: 0.9286\n",
      "Epoch 93/128\n",
      "3685/3685 [==============================] - 3s 707us/sample - loss: 0.1665 - acc: 0.9341 - val_loss: 0.1885 - val_acc: 0.9280\n",
      "Epoch 94/128\n",
      "3685/3685 [==============================] - 3s 770us/sample - loss: 0.1615 - acc: 0.9360 - val_loss: 0.1884 - val_acc: 0.9286\n",
      "Epoch 95/128\n",
      "3685/3685 [==============================] - 3s 757us/sample - loss: 0.1653 - acc: 0.9344 - val_loss: 0.1951 - val_acc: 0.9262\n",
      "Epoch 96/128\n",
      "3685/3685 [==============================] - 3s 738us/sample - loss: 0.1606 - acc: 0.9353 - val_loss: 0.1994 - val_acc: 0.9238\n",
      "Epoch 97/128\n",
      "3685/3685 [==============================] - 3s 689us/sample - loss: 0.1556 - acc: 0.9389 - val_loss: 0.1901 - val_acc: 0.9286\n",
      "Epoch 98/128\n",
      "3685/3685 [==============================] - 3s 701us/sample - loss: 0.1544 - acc: 0.9380 - val_loss: 0.1845 - val_acc: 0.9287\n",
      "Epoch 99/128\n",
      "3685/3685 [==============================] - 3s 698us/sample - loss: 0.1514 - acc: 0.9396 - val_loss: 0.1881 - val_acc: 0.9266\n",
      "Epoch 100/128\n",
      "3685/3685 [==============================] - 3s 725us/sample - loss: 0.1488 - acc: 0.9409 - val_loss: 0.1801 - val_acc: 0.9325\n",
      "Epoch 101/128\n",
      "3685/3685 [==============================] - 3s 709us/sample - loss: 0.1446 - acc: 0.9428 - val_loss: 0.1786 - val_acc: 0.9324\n",
      "Epoch 102/128\n",
      "3685/3685 [==============================] - 3s 710us/sample - loss: 0.1456 - acc: 0.9425 - val_loss: 0.1804 - val_acc: 0.9327\n",
      "Epoch 103/128\n",
      "3685/3685 [==============================] - 3s 761us/sample - loss: 0.1441 - acc: 0.9432 - val_loss: 0.1780 - val_acc: 0.9322\n",
      "Epoch 104/128\n",
      "3685/3685 [==============================] - 3s 704us/sample - loss: 0.1362 - acc: 0.9467 - val_loss: 0.1821 - val_acc: 0.9324\n",
      "Epoch 105/128\n",
      "3685/3685 [==============================] - 3s 698us/sample - loss: 0.1358 - acc: 0.9466 - val_loss: 0.1840 - val_acc: 0.9292\n",
      "Epoch 106/128\n",
      "3685/3685 [==============================] - 3s 708us/sample - loss: 0.1441 - acc: 0.9429 - val_loss: 0.1746 - val_acc: 0.9335\n",
      "Epoch 107/128\n",
      "3685/3685 [==============================] - 3s 769us/sample - loss: 0.1330 - acc: 0.9475 - val_loss: 0.1772 - val_acc: 0.9331\n",
      "Epoch 108/128\n",
      "3685/3685 [==============================] - 3s 794us/sample - loss: 0.1290 - acc: 0.9488 - val_loss: 0.1742 - val_acc: 0.9349\n",
      "Epoch 109/128\n",
      "3685/3685 [==============================] - 3s 762us/sample - loss: 0.1277 - acc: 0.9491 - val_loss: 0.1759 - val_acc: 0.9334\n",
      "Epoch 110/128\n",
      "3685/3685 [==============================] - 3s 756us/sample - loss: 0.1244 - acc: 0.9504 - val_loss: 0.1798 - val_acc: 0.9331\n",
      "Epoch 111/128\n",
      "3685/3685 [==============================] - 3s 726us/sample - loss: 0.1269 - acc: 0.9491 - val_loss: 0.1801 - val_acc: 0.9342\n",
      "Epoch 112/128\n",
      "3685/3685 [==============================] - 3s 717us/sample - loss: 0.1289 - acc: 0.9487 - val_loss: 0.1709 - val_acc: 0.9358\n",
      "Epoch 113/128\n",
      "3685/3685 [==============================] - 3s 707us/sample - loss: 0.1238 - acc: 0.9511 - val_loss: 0.1710 - val_acc: 0.9357\n",
      "Epoch 114/128\n",
      "3685/3685 [==============================] - 3s 697us/sample - loss: 0.1213 - acc: 0.9520 - val_loss: 0.1742 - val_acc: 0.9360\n",
      "Epoch 115/128\n",
      "3685/3685 [==============================] - 3s 828us/sample - loss: 0.1189 - acc: 0.9531 - val_loss: 0.1741 - val_acc: 0.9354\n",
      "Epoch 116/128\n",
      "3685/3685 [==============================] - 3s 751us/sample - loss: 0.1161 - acc: 0.9547 - val_loss: 0.1765 - val_acc: 0.9362\n",
      "Epoch 117/128\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3685/3685 [==============================] - 3s 718us/sample - loss: 0.1178 - acc: 0.9536 - val_loss: 0.1764 - val_acc: 0.9346\n",
      "Epoch 118/128\n",
      "3685/3685 [==============================] - 3s 738us/sample - loss: 0.1110 - acc: 0.9569 - val_loss: 0.1820 - val_acc: 0.9342\n",
      "Epoch 119/128\n",
      "3685/3685 [==============================] - 3s 716us/sample - loss: 0.1114 - acc: 0.9568 - val_loss: 0.1782 - val_acc: 0.9359\n",
      "Epoch 120/128\n",
      "3685/3685 [==============================] - 3s 732us/sample - loss: 0.1102 - acc: 0.9567 - val_loss: 0.1747 - val_acc: 0.9364\n",
      "Epoch 121/128\n",
      "3685/3685 [==============================] - 3s 700us/sample - loss: 0.1067 - acc: 0.9590 - val_loss: 0.1761 - val_acc: 0.9366\n",
      "Epoch 122/128\n",
      "3685/3685 [==============================] - 3s 698us/sample - loss: 0.1074 - acc: 0.9589 - val_loss: 0.1889 - val_acc: 0.9319\n",
      "Epoch 123/128\n",
      "3685/3685 [==============================] - 3s 789us/sample - loss: 0.1125 - acc: 0.9565 - val_loss: 0.1848 - val_acc: 0.9322\n",
      "Epoch 124/128\n",
      "3685/3685 [==============================] - 3s 770us/sample - loss: 0.1060 - acc: 0.9586 - val_loss: 0.1798 - val_acc: 0.9370\n",
      "Epoch 125/128\n",
      "3685/3685 [==============================] - 3s 766us/sample - loss: 0.1025 - acc: 0.9599 - val_loss: 0.1855 - val_acc: 0.9370\n",
      "Epoch 126/128\n",
      "3685/3685 [==============================] - 3s 684us/sample - loss: 0.1044 - acc: 0.9588 - val_loss: 0.1744 - val_acc: 0.9371\n",
      "Epoch 127/128\n",
      "3685/3685 [==============================] - 3s 702us/sample - loss: 0.1020 - acc: 0.9603 - val_loss: 0.1827 - val_acc: 0.9346\n",
      "Epoch 128/128\n",
      "3685/3685 [==============================] - 3s 689us/sample - loss: 0.0996 - acc: 0.9611 - val_loss: 0.1804 - val_acc: 0.9363\n"
     ]
    }
   ],
   "source": [
    "for dense_layer in dense_layers:\n",
    "    for layer_size in layer_sizes:\n",
    "        for conv_layer in conv_layers:\n",
    "            NAME = \"{}-conv-{}-nodes-{}-dense-{}\".format(conv_layer, layer_size, dense_layer, int(time.time()))\n",
    "            print(NAME)\n",
    "\n",
    "            model = Sequential()\n",
    "\n",
    "            model.add(Conv2D(layer_size, (3, 3), input_shape=x.shape[1:]))\n",
    "            model.add(Activation('relu'))\n",
    "            model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "            for l in range(conv_layer-1):\n",
    "                model.add(Conv2D(layer_size, (3, 3)))\n",
    "                model.add(Activation('relu'))\n",
    "                model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "            model.add(Flatten())\n",
    "\n",
    "            for _ in range(dense_layer):\n",
    "                model.add(Dense(layer_size))\n",
    "                model.add(Activation('relu'))\n",
    "\n",
    "            model.add(Dense(12))\n",
    "            model.add(Activation('sigmoid'))\n",
    "\n",
    "            tensorboard = TensorBoard(log_dir=\"logs/{}\".format(NAME))\n",
    "\n",
    "            model.compile(loss='binary_crossentropy',\n",
    "                          optimizer='adam',\n",
    "                          metrics=['accuracy'],\n",
    "                          )\n",
    "\n",
    "            model.fit(x, y,\n",
    "                      batch_size=64,\n",
    "                      epochs=128,    # more than 9 epochs will cause overfitting in this case\n",
    "                      validation_split=0.3,\n",
    "                      callbacks=[tensorboard])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('4-25-6-silver')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
